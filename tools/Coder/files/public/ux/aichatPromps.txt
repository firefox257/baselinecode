

lets add a conversation mode. 
in the settings add a check mark to have concersation enabled.
if checked show a dropdown a list of tts voices.
when selected cache the selection on browsers local storage.

add a conversation unicode icon button to enter conversation mode.
when the conversation setting is checked show the button.
in conversation mode will overlay on topof the ai-chat which becomes one big button. 
with a small button on the bottom to exit conversation.
when the big conversation button is pressed tts will say "Start".
then the speatch to text start listening.
when the big conversation button is pressed again then the listening stops. 
finish with the speach to text then have tts say stop. 
for all ai responses tts speaks the responses.

make sure the conversation shows up in the response text box.

===========
html js create a module for for ai chat that can be imported.

It will have a special tag <aichat> in html.
on load all <aichat> will be replaced with the ai
chat ux. for any dom added will be detected to see if it is the <aichat> tag and create the ai chat.
the ai chat will span out in what ever container.
use mono space font.

use the following code for the streaming as reference.



<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Streaming AI Story</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f4f4f4;
            color: #333;
        }
        .container {
            background-color: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            max-width: 800px;
            margin: auto;
        }
        .input-group {
            margin-bottom: 15px;
        }
        .input-group label {
            display: block;
            margin-bottom: 5px;
            font-weight: bold;
        }
        .input-group input[type="text"],
        .input-group textarea,
        .input-group input[type="number"] {
            width: calc(100% - 22px); /* Account for padding and border */
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
            font-size: 16px;
        }
        .input-group textarea {
            min-height: 80px;
            resize: vertical;
        }
        #sendButton {
            padding: 10px 15px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
            width: 100%;
            box-sizing: border-box; /* Ensure padding and border are included in the width */
        }
        #sendButton:hover {
            background-color: #0056b3;
        }
        #rawTextOutput {
            margin-top: 20px;
            padding: 15px;
            border: 1px solid #ddd;
            border-radius: 5px;
            background-color: #e9ecef;
            white-space: pre-wrap;
            word-wrap: break-word;
            max-height: 400px;
            overflow-y: auto;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Streaming AI Story Generator</h1>
        <p>Enter your prompt and click **Send** to get a story from the AI.</p>

        <div class="input-group">
            <label for="systemInput">System Message:</label>
            <textarea id="systemInput">You are a helpful assistant that generates creative stories.</textarea>
        </div>

        <div class="input-group">
            <label for="temperatureInput">Temperature (0.0 - 1.0):</label>
            <input type="number" id="temperatureInput" value="0.7" min="0" max="1" step="0.1">
        </div>

        <div class="input-group">
            <label for="textInput">User Prompt:</label>
            <textarea id="textInput" placeholder="Enter your prompt here..."></textarea>
        </div>

        <button id="sendButton">Send</button>

        <div id="rawTextOutput">
            Loading...
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const textInput = document.getElementById('textInput');
            const systemInput = document.getElementById('systemInput');
            const temperatureInput = document.getElementById('temperatureInput');
            const sendButton = document.getElementById('sendButton');
            const rawTextOutputDiv = document.getElementById('rawTextOutput');

            sendButton.addEventListener('click', async () => {
                const userPrompt = textInput.value.trim();
                const systemMessage = systemInput.value.trim();
                const temperature = parseFloat(temperatureInput.value);

                if (!userPrompt) {
                    rawTextOutputDiv.textContent = 'Please enter a user prompt.';
                    return;
                }

                if (isNaN(temperature) || temperature < 0 || temperature > 1) {
                    rawTextOutputDiv.textContent = 'Please enter a valid temperature between 0.0 and 1.0.';
                    return;
                }

                rawTextOutputDiv.textContent = 'Generating response...';

                const url = "https://text.pollinations.ai/openai";
                const payload = {
                    "model": "mistral",
                    "messages": [
                        {"role": "system", "content": systemMessage},
                        {"role": "user", "content": userPrompt}
                    ],
                    "temperature": temperature,
                    "stream": true,
                    "private": false
                };

                try {
                    const response = await fetch(url, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'Accept': 'text/event-stream'
                        },
                        body: JSON.stringify(payload)
                    });

                    if (!response.ok) {
                        throw new Error(`HTTP error! status: ${response.status}`);
                    }

                    const reader = response.body.getReader();
                    const decoder = new TextDecoder('utf-8');
                    let fullResponse = '';

                    rawTextOutputDiv.textContent = '';

                    while (true) {
                        const { done, value } = await reader.read();
                        if (done) {
                            console.log("Stream finished.");
                            break;
                        }

                        const chunk = decoder.decode(value, { stream: true });
                        const events = chunk.split('\n\n').filter(Boolean);

                        for (const eventString of events) {
                            if (eventString.startsWith('data:')) {
                                const data = eventString.substring(5).trim();

                                if (data === '[DONE]') {
                                    console.log("Stream finished by [DONE] marker.");
                                    reader.cancel();
                                    break;
                                }

                                try {
                                    const parsedChunk = JSON.parse(data);
                                    const content = parsedChunk.choices && parsedChunk.choices[0] && parsedChunk.choices[0].delta && parsedChunk.choices[0].delta.content;

                                    if (content) {
                                        fullResponse += content;
                                        rawTextOutputDiv.textContent = fullResponse;
                                        rawTextOutputDiv.scrollTop = rawTextOutputDiv.scrollHeight;
                                    }
                                } catch (jsonError) {
                                    console.warn("Received non-JSON data or marker:", data);
                                }
                            }
                        }
                    }
                    console.log("--- End of Stream ---");

                } catch (error) {
                    console.error("Error:", error);
                    rawTextOutputDiv.textContent = `Error: ${error.message}`;
                }
            });
        });
    </script>
</body>
</html>

use the following to get the list of models https://text.pollinations.ai/models
the following is the output of that call.
[
    {
        "name": "deepseek",
        "description": "DeepSeek V3",
        "provider": "azure",
        "tier": "seed",
        "community": false,
        "aliases": "deepseek-v3",
        "input_modalities": [
            "text"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": false,
        "vision": false,
        "audio": false
    },
    {
        "name": "deepseek-reasoning",
        "description": "DeepSeek R1 0528",
        "reasoning": true,
        "provider": "azure",
        "tier": "seed",
        "community": false,
        "aliases": "deepseek-r1-0528",
        "input_modalities": [
            "text"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": false,
        "vision": false,
        "audio": false
    },
    {
        "name": "grok",
        "description": "xAI Grok-3 Mini",
        "provider": "azure",
        "tier": "seed",
        "community": false,
        "aliases": "grok-3-mini",
        "input_modalities": [
            "text"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": false,
        "audio": false
    },
    {
        "name": "llamascout",
        "description": "Llama 4 Scout 17B",
        "provider": "cloudflare",
        "tier": "anonymous",
        "community": false,
        "aliases": "llama-4-scout-17b-16e-instruct",
        "input_modalities": [
            "text"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": false,
        "vision": false,
        "audio": false
    },
    {
        "name": "mistral",
        "description": "Mistral Small 3.1 24B",
        "provider": "cloudflare",
        "tier": "anonymous",
        "community": false,
        "aliases": "mistral-small-3.1-24b-instruct",
        "input_modalities": [
            "text",
            "image"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": true,
        "audio": false
    },
    {
        "name": "openai",
        "description": "OpenAI GPT-4o Mini",
        "provider": "azure",
        "tier": "anonymous",
        "community": false,
        "aliases": "gpt-4o-mini",
        "input_modalities": [
            "text",
            "image"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": true,
        "audio": false
    },
    {
        "name": "openai-audio",
        "description": "OpenAI GPT-4o Mini Audio Preview",
        "maxInputChars": 1000,
        "voices": [
            "alloy",
            "echo",
            "fable",
            "onyx",
            "nova",
            "shimmer",
            "coral",
            "verse",
            "ballad",
            "ash",
            "sage",
            "amuch",
            "dan"
        ],
        "provider": "azure",
        "tier": "seed",
        "community": false,
        "aliases": "gpt-4o-mini-audio-preview",
        "input_modalities": [
            "text",
            "image",
            "audio"
        ],
        "output_modalities": [
            "audio",
            "text"
        ],
        "tools": true,
        "vision": true,
        "audio": true
    },
    {
        "name": "openai-fast",
        "description": "OpenAI GPT-4.1 Nano",
        "provider": "azure",
        "tier": "anonymous",
        "community": false,
        "aliases": "gpt-4.1-nano",
        "input_modalities": [
            "text",
            "image"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": true,
        "audio": false
    },
    {
        "name": "openai-large",
        "description": "OpenAI GPT-4.1",
        "provider": "azure",
        "tier": "seed",
        "community": false,
        "aliases": "gpt-4.1",
        "input_modalities": [
            "text",
            "image"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": true,
        "audio": false
    },
    {
        "name": "openai-reasoning",
        "description": "OpenAI O3 (provided by chatwithmono.xyz)",
        "reasoning": true,
        "provider": "chatwithmono.xyz",
        "tier": "anonymous",
        "community": false,
        "aliases": "o3",
        "input_modalities": [
            "text",
            "image"
        ],
        "output_modalities": [
            "text"
        ],
        "vision": true,
        "audio": false
    },
    {
        "name": "openai-roblox",
        "description": "OpenAI GPT-4.1 Mini (Roblox)",
        "provider": "azure",
        "tier": "flower",
        "community": false,
        "aliases": "gpt-4.1-mini-roblox",
        "input_modalities": [
            "text",
            "image"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": true,
        "audio": false
    },
    {
        "name": "phi",
        "description": "Phi-4 Mini Instruct",
        "provider": "azure",
        "tier": "anonymous",
        "community": false,
        "aliases": "phi-4-mini-instruct",
        "input_modalities": [
            "text",
            "image",
            "audio"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": false,
        "vision": true,
        "audio": true
    },
    {
        "name": "qwen-coder",
        "description": "Qwen 2.5 Coder 32B",
        "provider": "scaleway",
        "tier": "anonymous",
        "community": false,
        "aliases": "qwen2.5-coder-32b-instruct",
        "input_modalities": [
            "text"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": false,
        "audio": false
    },
    {
        "name": "searchgpt",
        "description": "OpenAI GPT-4o Mini Search Preview (provided by chatwithmono.xyz)",
        "search": true,
        "provider": "chatwithmono.xyz",
        "tier": "anonymous",
        "community": false,
        "aliases": "gpt-4o-mini-search",
        "input_modalities": [
            "text"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": false,
        "audio": false
    },
    {
        "name": "bidara",
        "description": "BIDARA (Biomimetic Designer and Research Assistant by NASA)",
        "provider": "azure",
        "tier": "anonymous",
        "community": true,
        "input_modalities": [
            "text",
            "image"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": true,
        "audio": false
    },
    {
        "name": "elixposearch",
        "description": "Elixpo Search",
        "provider": "scaleway",
        "tier": "anonymous",
        "community": true,
        "input_modalities": [
            "text"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": false,
        "vision": false,
        "audio": false
    },
    {
        "name": "evil",
        "description": "Evil",
        "provider": "cloudflare",
        "uncensored": true,
        "tier": "seed",
        "community": true,
        "input_modalities": [
            "text",
            "image"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": true,
        "audio": false
    },
    {
        "name": "hypnosis-tracy",
        "description": "Hypnosis Tracy",
        "provider": "azure",
        "tier": "seed",
        "community": true,
        "input_modalities": [
            "text",
            "audio"
        ],
        "output_modalities": [
            "audio",
            "text"
        ],
        "tools": true,
        "vision": false,
        "audio": true
    },
    {
        "name": "midijourney",
        "description": "MIDIjourney",
        "provider": "azure",
        "tier": "anonymous",
        "community": true,
        "input_modalities": [
            "text"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": false,
        "audio": false
    },
    {
        "name": "mirexa",
        "description": "Mirexa AI Companion",
        "provider": "azure",
        "tier": "seed",
        "community": true,
        "input_modalities": [
            "text",
            "image"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": true,
        "audio": false
    },
    {
        "name": "rtist",
        "description": "Rtist",
        "provider": "azure",
        "tier": "seed",
        "community": true,
        "input_modalities": [
            "text"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": false,
        "audio": false
    },
    {
        "name": "sur",
        "description": "Sur AI Assistant",
        "provider": "cloudflare",
        "tier": "seed",
        "community": true,
        "input_modalities": [
            "text",
            "image"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": true,
        "audio": false
    },
    {
        "name": "unity",
        "description": "Unity Unrestricted Agent",
        "provider": "cloudflare",
        "uncensored": true,
        "tier": "seed",
        "community": true,
        "input_modalities": [
            "text",
            "image"
        ],
        "output_modalities": [
            "text"
        ],
        "tools": true,
        "vision": true,
        "audio": false
    }
]

make a menu top with unicode icon buttoms. 
have a button for the system prompt.
another for a dropdown to select the type of llm to use.


one to show a system portion for the prompts.
have an onClose event at the dome level. if it is defined then show the onClise menu button.
add a tutle property on the dom level and a title bar. if it is defined shiw the title bar.
make sure the end of the title always shows. no "..." 


for the response area use an editable div. 
make the prompet input text use dive editable as well and on the bottom. 
use a unicode icon for tue send button.